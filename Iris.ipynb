{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Classification using PySpark-ml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer,IndexToString,VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "# Building the Spark Session\n",
    "# Befire 2.0.0, the main connection objects were 'SaprkContext,SqlContext, and HiveContext'\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Iris_Spark_ML\") \\\n",
    "        .config('spark.some.config.option','some-value') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# here, 'spark' is an object of SparkSession, which has the 'SparkContext' object and can be accessed directly\n",
    "sc = spark.sparkContext\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading the data from 'csv'\n",
    "Iris = spark.read \\\n",
    "    .format('com.databricks.spark.csv') \\\n",
    "    .option('header','true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load('/home/ramscrux7757/SPARK/Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Iris.count(), len(Iris.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'SepalLengthCm',\n",
       " 'SepalWidthCm',\n",
       " 'PetalLengthCm',\n",
       " 'PetalWidthCm',\n",
       " 'Species']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Renaming the iris columns to their standard names\n",
    "Iris = Iris.withColumnRenamed('SepalLengthCm','SepalLength') \\\n",
    "           .withColumnRenamed('SepalWidthCm','SepalWidth') \\\n",
    "           .withColumnRenamed('PetalLengthCm','PetalLength') \\\n",
    "           .withColumnRenamed('PetalWidthCm','PetalWidth') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-----------+\n",
      "| Id|SepalLength|SepalWidth|PetalLength|PetalWidth|    Species|\n",
      "+---+-----------+----------+-----------+----------+-----------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+---+-----------+----------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Always limit it first if you want to use pandas\n",
    "Iris.limit(5).show()\n",
    "#Iris.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SepalLength', 'double'), ('SepalWidth', 'double'), ('PetalLength', 'double'), ('PetalWidth', 'double'), ('Species', 'string')]\n",
      "root\n",
      " |-- SepalLength: double (nullable = true)\n",
      " |-- SepalWidth: double (nullable = true)\n",
      " |-- PetalLength: double (nullable = true)\n",
      " |-- PetalWidth: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Iris = Iris.drop('ID')\n",
    "print(Iris.dtypes)\n",
    "print(Iris.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+\n",
      "|summary|       SepalLength|         SepalWidth|       PetalLength|        PetalWidth|\n",
      "+-------+------------------+-------------------+------------------+------------------+\n",
      "|  count|               150|                150|               150|               150|\n",
      "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|\n",
      "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|\n",
      "+-------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Iris.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|        Species|\n",
      "+---------------+\n",
      "| Iris-virginica|\n",
      "|    Iris-setosa|\n",
      "|Iris-versicolor|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of distinct classes in 'Species'\n",
    "Iris.createOrReplaceTempView('View1')\n",
    "spark.sql('select Distinct(Species) from View1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|        Species|count|\n",
      "+---------------+-----+\n",
      "| Iris-virginica|   50|\n",
      "|    Iris-setosa|   50|\n",
      "|Iris-versicolor|   50|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifying the counts in each class of Species\n",
    "Iris.groupBy(\"Species\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|          0|         0|          0|         0|      0|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in each column\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "Iris.select([count(when(isnan(c),c)).alias(c)  for c in Iris.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species  \\\n",
      "0          5.1         3.5          1.4         0.2  Iris-setosa   \n",
      "1          4.9         3.0          1.4         0.2  Iris-setosa   \n",
      "2          4.7         3.2          1.3         0.2  Iris-setosa   \n",
      "3          4.6         3.1          1.5         0.2  Iris-setosa   \n",
      "4          5.0         3.6          1.4         0.2  Iris-setosa   \n",
      "\n",
      "               features  Label  \n",
      "0  [5.1, 3.5, 1.4, 0.2]    0.0  \n",
      "1  [4.9, 3.0, 1.4, 0.2]    0.0  \n",
      "2  [4.7, 3.2, 1.3, 0.2]    0.0  \n",
      "3  [4.6, 3.1, 1.5, 0.2]    0.0  \n",
      "4  [5.0, 3.6, 1.4, 0.2]    0.0  \n"
     ]
    }
   ],
   "source": [
    "# Spark ML specific Transformations\n",
    "# The following will add two columns to the dataset ('features (a vector of all predictors) and Labeled categorical column)\n",
    "# The ml algorithm can straightaway take these two columns \n",
    "\n",
    "# Prepare the data by indexing the classes and putting the features into a vector.\n",
    "speciesIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"Label\")\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\"],\n",
    "                                  outputCol=\"features\")\n",
    "\n",
    "iris_pred_vector = vectorAssembler.transform(Iris) # it collects the predictor variable names\n",
    "index_model = speciesIndexer.fit(iris_pred_vector) # about the target variable\n",
    "iris_data_indexed = index_model.transform(iris_pred_vector) # creates the 'features' and 'Labels' \n",
    "# ('features' and 'Labels' will be feeded into the model straightaway)\n",
    "\n",
    "print(iris_data_indexed.limit(5)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing a Classification Model\n",
    "\n",
    "# Split the data into training and test sets.\n",
    "train, test =  iris_data_indexed.randomSplit([0.7, 0.3],123) # seed=123\n",
    "\n",
    "# Configure the classifier and then train it using the training set.\n",
    "rf = RandomForestClassifier(labelCol='Label', featuresCol='features',numTrees=100, maxDepth=4,maxBins=32)\n",
    "model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+\n",
      "|        Species|PredictedSpecies|\n",
      "+---------------+----------------+\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|Iris-versicolor| Iris-versicolor|\n",
      "| Iris-virginica| Iris-versicolor|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "|    Iris-setosa|     Iris-setosa|\n",
      "+---------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the classifier on the test set\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Un-index the data so we have the species names rather than the index numbers in our output.\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"PredictedSpecies\", labels=index_model.labels)\n",
    "converted = converter.transform(predictions)\n",
    "\n",
    "# Display the actual and predicted species side-by-side\n",
    "converted.select(['Species','PredictedSpecies']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.96\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. (default: 10)\n",
      "featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2 (0.0-1.0], [1-n]. (default: auto)\n",
      "featuresCol: features column name. (default: features, current: features)\n",
      "impurity: Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini (default: gini)\n",
      "labelCol: label column name. (default: label, current: speciesIndex)\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32)\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5)\n",
      "maxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\n",
      "minInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\n",
      "numTrees: Number of trees to train (>= 1). (default: 20, current: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "seed: random seed. (default: -4140900678877021401)\n",
      "subsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (undefined)\n"
     ]
    }
   ],
   "source": [
    "# The following will lists the hyper parameters available for the selected classifier\n",
    "print(rf.explainParams()) # gives the details about the hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try with Cross-validation and parameter tuning\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(rf.maxDepth, [2,4,6])\n",
    "            #.addGrid(rf.maxBins, [20,60])\n",
    "            .addGrid(rf.numTrees, [50, 100, 200])\n",
    "            .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\n",
    "cvModel = cv.fit(train)\n",
    "\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(test)\n",
    "\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
